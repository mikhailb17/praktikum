{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Классификация комментариев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем необходимые библиотеки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import re\n",
    "import warnings\n",
    "from tqdm import notebook\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прочитаем файл и сохраним его в переменной *comments*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = pd.read_csv('/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим таблицу и общую информацию о ней."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>121611</td>\n",
       "      <td>Back Door Key \\n\\nA colleague of mine, who is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134727</td>\n",
       "      <td>REDIRECT Talk:Lega Basket A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42260</td>\n",
       "      <td>Natalie Started as a Correspondent and Sub anc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82596</td>\n",
       "      <td>Military history WikiProject Newsletter - Issu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150578</td>\n",
       "      <td>\"\\n\\n Thank you for the Barnstar \\n\\nDear Dani...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "121611  Back Door Key \\n\\nA colleague of mine, who is ...      0\n",
       "134727                        REDIRECT Talk:Lega Basket A      0\n",
       "42260   Natalie Started as a Correspondent and Sub anc...      0\n",
       "82596   Military history WikiProject Newsletter - Issu...      0\n",
       "150578  \"\\n\\n Thank you for the Barnstar \\n\\nDear Dani...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      "text     159571 non-null object\n",
      "toxic    159571 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "display(comments.sample(5))\n",
    "comments.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датафрейм содержит 159571 строк и столбцы с комментариями на английском языке и бинарными оценками их токсичности. Очистим комментарии от лишних символов, оставив только буквы английского алфавита. Сохраним результат в столбце *cleared*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccd372f3af14492099e7d5d93b8582c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=159571.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def clear(comment):\n",
    "    cleared = re.sub(r'[^a-zA-Z]', ' ', comment)    \n",
    "    return cleared\n",
    "\n",
    "notebook.tqdm.pandas()\n",
    "\n",
    "comments['cleared'] = comments['text'].progress_apply(clear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведём лемматизацию очищенных комментариев с удалением стоп-слов. Сохраним результат в столбце *lemmatized*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba867eb0088b43f085899833fb26a5d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=159571.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def lemmatize(comment):  \n",
    "    doc = nlp(comment)\n",
    "    lemmatized = ' '.join([token.lemma_ for token in doc if (token.is_stop==False) & \\\n",
    "                                                            (token.shape_ not in ['x', 'X']) & \\\n",
    "                                                            (token.pos_!='SPACE')])\n",
    "    return lemmatized\n",
    "\n",
    "comments['lemmatized'] = comments['cleared'].progress_apply(lemmatize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим успешность очистки и лемматизации комментариев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments[['text', 'cleared', 'lemmatized', 'toxic']].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После удаления стоп-слов в данных могли появиться пропуски. Удалим строки, которые их содержат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = comments.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модели на лемматизированных и не лемматизированных данных, а также с использованием и без использования биграмм. Для этого создадим словарь *d* с возможными комбинациями параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {0: ['cleared', 1],\n",
    "     1: ['cleared', 2],\n",
    "     2: ['lemmatized', 1],\n",
    "     3: ['lemmatized', 2]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим целевой признак и разделим датасет на обучающую и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = pd.DataFrame()\n",
    "features_test = pd.DataFrame()\n",
    "\n",
    "features_train['cleared'], features_test['cleared'], \\\n",
    "features_train['lemmatized'], features_test['lemmatized'], \\\n",
    "target_train, target_test = train_test_split(comments['cleared'],\n",
    "                                             comments['lemmatized'],\n",
    "                                             comments['toxic'],\n",
    "                                             test_size=0.2,\n",
    "                                             random_state=1,\n",
    "                                             stratify=comments['toxic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На основе словаря *d* обучим по сеткам с различными гиперпараметрами модели логистической регрессии и градиентного бустинга *LightGBM*. Определим гиперпараметры с наилучшими метриками F1 по итогам кросс-валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51441a634dfe4b73a518174ca974d753",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лемматизация: ✖  Биграммы: ✖ \n",
      "\n",
      "Логистическая регрессия\n",
      "Лучшие гиперпараметры:  {'C': 10.0, 'penalty': 'l2'}\n",
      "F1 = 0.77 \n",
      "\n",
      "LightGBM\n",
      "Лучшие гиперпараметры:  {'learning_rate': 0.30000000000000004, 'num_leaves': 15}\n",
      "F1 = 0.73\n",
      "————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Лемматизация: ✖  Биграммы: ✔ \n",
      "\n",
      "Логистическая регрессия\n",
      "Лучшие гиперпараметры:  {'C': 10.0, 'penalty': 'l1'}\n",
      "F1 = 0.78 \n",
      "\n",
      "LightGBM\n",
      "Лучшие гиперпараметры:  {'learning_rate': 0.30000000000000004, 'num_leaves': 15}\n",
      "F1 = 0.73\n",
      "————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Лемматизация: ✔  Биграммы: ✖ \n",
      "\n",
      "Логистическая регрессия\n",
      "Лучшие гиперпараметры:  {'C': 10.0, 'penalty': 'l2'}\n",
      "F1 = 0.76 \n",
      "\n",
      "LightGBM\n",
      "Лучшие гиперпараметры:  {'learning_rate': 0.30000000000000004, 'num_leaves': 15}\n",
      "F1 = 0.75\n",
      "————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Лемматизация: ✔  Биграммы: ✔ \n",
      "\n",
      "Логистическая регрессия\n",
      "Лучшие гиперпараметры:  {'C': 10.0, 'penalty': 'l2'}\n",
      "F1 = 0.78 \n",
      "\n",
      "LightGBM\n",
      "Лучшие гиперпараметры:  {'learning_rate': 0.2, 'num_leaves': 15}\n",
      "F1 = 0.74\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_results = {}\n",
    "lgbm_results = {}\n",
    "\n",
    "for i in notebook.tqdm(d):\n",
    "    print('Лемматизация: {:<2} Биграммы: {} \\n'.format(('✔' if d[i][0] == 'lemmatized' else '✖'),\n",
    "                                                       ('✔' if d[i][1] == 2 else '✖')))\n",
    "    # Векторизация\n",
    "    count_tf_idf_train = TfidfVectorizer(ngram_range=(1, d[i][1]))\n",
    "    tf_idf_train = count_tf_idf_train.fit_transform(features_train[d[i][0]])\n",
    "    tf_idf_test = count_tf_idf_train.transform(features_test[d[i][0]])\n",
    "    \n",
    "    # Логистическая регрессия\n",
    "    lr = LogisticRegression(random_state=1, class_weight='balanced', solver='liblinear')\n",
    "    lr_parameters = {'C': np.logspace(-2, 2, 5), \n",
    "                     'penalty': ['l1', 'l2']}\n",
    "    \n",
    "    lr_grid = GridSearchCV(lr, lr_parameters, cv=4, n_jobs=-1, scoring='f1')\n",
    "    lr_grid.fit(tf_idf_train, target_train)\n",
    "    \n",
    "    lr_results[i] = pd.DataFrame(lr_grid.cv_results_)\n",
    "    print('Логистическая регрессия')\n",
    "    print('Лучшие гиперпараметры: ', (lr_grid.best_params_))\n",
    "    print('F1 = {:.2f} \\n'.format(lr_grid.best_score_))\n",
    "    \n",
    "    # LightGBM\n",
    "    lgbm = LGBMClassifier(n_estimators=150, class_weight='balanced')\n",
    "    lgbm_parameters = {'learning_rate': np.arange(0.1, 0.31, 0.1),\n",
    "                       'num_leaves': [7, 15]}\n",
    "    lgbm_grid = GridSearchCV(lgbm, lgbm_parameters, cv=4, n_jobs=-1, scoring='f1')\n",
    "    lgbm_grid.fit(tf_idf_train, target_train)\n",
    "    \n",
    "    lgbm_results[i] = pd.DataFrame(lgbm_grid.cv_results_)\n",
    "    print('LightGBM')\n",
    "    print('Лучшие гиперпараметры: ', lgbm_grid.best_params_)\n",
    "    print('F1 = {:.2f}'.format(lgbm_grid.best_score_))\n",
    "    \n",
    "    if i < len(d)-1:\n",
    "        print('—' * 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все модели показали близкие результаты, однако качество предсказаний логистической регрессии немного выше, чем у *LightGBM*. Наилучшее значение метрики F1 (0.78) показали модели логистической регрессии, обученные на данных с использованием биграмм. Исследуем их результаты более подробно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Лемматизация: ✖\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>l1</td>\n",
       "      <td>48.191428</td>\n",
       "      <td>0.784939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>47.099354</td>\n",
       "      <td>0.782292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>l1</td>\n",
       "      <td>27.033905</td>\n",
       "      <td>0.781967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>l2</td>\n",
       "      <td>64.508006</td>\n",
       "      <td>0.781428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>l1</td>\n",
       "      <td>22.455938</td>\n",
       "      <td>0.752586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_C param_penalty  mean_fit_time  mean_test_score\n",
       "6      10            l1      48.191428         0.784939\n",
       "7      10            l2      47.099354         0.782292\n",
       "8     100            l1      27.033905         0.781967\n",
       "9     100            l2      64.508006         0.781428\n",
       "4       1            l1      22.455938         0.752586"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Лемматизация: ✔\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>29.272216</td>\n",
       "      <td>0.778280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>l1</td>\n",
       "      <td>1830.626293</td>\n",
       "      <td>0.777992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>l1</td>\n",
       "      <td>33.939060</td>\n",
       "      <td>0.775412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>l2</td>\n",
       "      <td>45.879880</td>\n",
       "      <td>0.774798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>16.684891</td>\n",
       "      <td>0.760014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_C param_penalty  mean_fit_time  mean_test_score\n",
       "7      10            l2      29.272216         0.778280\n",
       "6      10            l1    1830.626293         0.777992\n",
       "8     100            l1      33.939060         0.775412\n",
       "9     100            l2      45.879880         0.774798\n",
       "5       1            l2      16.684891         0.760014"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in [1, 3]:\n",
    "    print('\\n Лемматизация: {}'.format(('✔' if d[i][0] == 'lemmatized' else '✖')))\n",
    "    display(lr_results[i].iloc[:, [4, 5, 0, 11]].sort_values('mean_test_score', ascending=False).head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из полученных таблиц видно, что качество моделей, обученных на нелемматизированных данных, немного выше. При этом время их обучения имеет тот же порядок (за исключением аномально долгого обучения одной из моделей на лемматизированных данных), а с учётом отсутствия временных затрат на лемматизацию они работают даже быстрее. Исходя из этого, в качестве финальной модели выберем модель логистической регрессии с l1-регуляризацией и обратным коэффициентом регуляризации, равным 10, F1 которой на кросс-валидации составила 0.7849. Обучим её на всей тренировочной выборке без лемматизации, а также с использованием униграмм и биграмм. Проверим качество предсказаний на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 = 0.7809\n"
     ]
    }
   ],
   "source": [
    "# Векторизация\n",
    "count_tf_idf_train = TfidfVectorizer(ngram_range=(1, 2))\n",
    "tf_idf_train = count_tf_idf_train.fit_transform(features_train['cleared'])\n",
    "tf_idf_test = count_tf_idf_train.transform(features_test['cleared'])\n",
    "\n",
    "# Логистическая регрессия\n",
    "lr = LogisticRegression(random_state=1, class_weight='balanced', solver='liblinear', C=10, penalty='l1')\n",
    "lr.fit(tf_idf_train, target_train)\n",
    "predicted = lr.predict(tf_idf_test)\n",
    "print('F1 = {:.4f}'.format(f1_score(target_test, predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, итоговая метрика F1 на тестовой выборке составила 0.7809, что соответствует целевому показателю. Также можно отметить, что качество почти не изменилось по сравнению со значением, полученным на кросс-валидации. Это говорит о том, что удалось избежать переобучения модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе выполнения проекта проведена подготовка данных — тексты комментариев очищены от лишних символов и проведена лемматизция с удалением стоп-слов; на данных с лемматизацией и без неё, с использованием и без использования биграмм в дополнение к униграммам обучены модели логистической регрессии и градиентного бустинга на основе библиотеки *LightGBM* c различными гиперпараметрами. Установлено, что модели градиентного бустинга немного уступают в качестве моделям логистической регрессии. Наилучшего результата удалось достичь при обучении на нелемматизированных данных с использованием униграмм и биграмм. В качестве финальной выбрана модель логистической регрессии со следующими гиперпараметрами:\n",
    "* class_weight='balanced';\n",
    "* solver='liblinear';\n",
    "* C=10;\n",
    "* penalty='l1'.\n",
    "\n",
    "Проведена проверка данной модели на тестовой выборке. Итоговая метрика F1 оказалась равна 0.7809."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
